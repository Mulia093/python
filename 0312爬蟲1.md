@@ -1,10 +1,18 @@
#
# 爬蟲初體驗
```
教科書
Python 網路爬蟲與資料分析入門實戰
繁體中文/林俊瑋、林修博/博碩文化出版日期：2018-10-04
https://github.com/jwlin/py-scraping-analysis-book
ch1
```
# 體驗1
## web page
```
http://blog.castman.net/py-scraping-analysis-book/ch1/connect.html
```

### code
### web page::code
```
<!DOCTYPE html>
@@ -101,3 +109,34 @@ requests.get('https://jwlin.github.io/py-scraping-analysis-book/ch1/connect.html
soup.find('h1') ==> 找出解析後的檔案你要的部分
```
# 體驗2
```
import requests
from bs4 import BeautifulSoup
def main():
    url1 = 'http://jwlin.github.io/py-scraping-analysis-book/ch1/connect.html'
    bad_url = 'http://non-existed.domain/connect.html'
    text1 = get_tag_text(url1, 'h1')
    print(text1)
    text2 = get_tag_text(url1, 'h2')
    print(text2)
    text3 = get_tag_text(bad_url, 'h1')
    print(text3)
def get_tag_text(url, tag):
    try:
        resp = requests.get(url)
        if resp.status_code == 200:
            soup = BeautifulSoup(resp.text, 'html.parser')
            return soup.find(tag).text
    except Exception as e:
        print('Exception: %s' %(e))
    return None
if __name__ == '__main__':
    main()
```
